## 专题二改善深层神经网络
> 介绍：
>> 本专题又三丈的内容组成：深度学习的实用层面、优化算法、超参数调试<br>主要讲了神经网络的改进的一些思想:<br>
>>
>> **深度学习的实用层面** 主要是对神经网络的改进提供了很多思想,包括方差偏差的概念，正则化的思想（L2正则化，Dropout正则化的理解，其他正则化方法），梯度消失
和梯度爆炸，神经网络的权重初始化， 梯度检验等<br>
>> **优化算法** 主要讲了训练神经网络的时候其他的一些优化方法， 像mini-batch梯度下降，指数加权平均的概念，动量梯度下降，RMSprop，Adam梯度下降方法，
学习率衰减的知识<br>
>> **超参数调试** 讲了超参数在选择时候的一些思想，主要包括调试处理，为超参数选择合适的范围，Batch正则化，Softmax回归，深度学习框架涉及了一点。
>
> 重难点：
>> *  第一章的重点在于要理解偏差和方差以及什么时候会产生偏差和方差，正则化的思想，尤其是Dropout正则化怎么回事，以及为什么有效要重点理解，在实践中会使用
为什么需要神经网络的权重初始化等。<br>
>> * 第二章的优化算法，要理解min-batch是怎么回事，理解指数滑动平均的概念，以及四种优化方法：Mini-batch梯度下降，Momentum梯度下降，RMSProp和
Adam梯度下降，重点要会Adam梯度下降方法， 以及为什么需要学习率衰减<br>
>> * 第三章要理解一些改进思想，比如训练集交叉集合测试集的选取，重点是Batch正则化，理解Batch正则化为什么有效，为什么需要Batch正则化，也要回使用
Batch正则化， 然后要理解Sortmax回归是干什么用的，怎么用， TensorFlow框架要会使用。
>
> 笔记链接：
>>听课过程中的笔记都记录在有道云笔记：
>> * [第1讲 - 深度学习的实用层面](http://note.youdao.com/noteshare?id=7c4ac6c3a44cdf008dbc2b7a9c3db814&sub=DC8E8C39F1164BC99411D8155EE84E35)
>> * [第2讲 - 优化算法](http://note.youdao.com/noteshare?id=a70402cd3388d8e0a6df8f1ce33520c7&sub=752E9136CD9F4F3CB2FDBC5304FDBDCB)
>> * [第3讲 - 超参数调优、Batch正则化和程序框架](http://note.youdao.com/noteshare?id=8409e2ca8818b95874b5c8e637705a12&sub=F4D91376BDA142C9BFAE9CBC9A24E929)
